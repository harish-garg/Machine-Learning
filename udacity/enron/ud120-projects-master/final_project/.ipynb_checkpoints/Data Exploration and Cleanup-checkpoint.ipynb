{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tester import test_classifier, dump_classifier_and_data\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "features_list = ['poi','salary','deferral_payments', 'total_payments', 'loan_advances',\n",
    "                 'bonus', 'restricted_stock_deferred', 'deferred_income', 'total_stock_value', \n",
    "                 'expenses', 'exercised_stock_options', 'other', 'long_term_incentive', \n",
    "                 'restricted_stock', 'director_fees', 'to_messages', 'from_poi_to_this_person', \n",
    "                 'from_messages', 'from_this_person_to_poi', \n",
    "                 'shared_receipt_with_poi'] # You will need to use more features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of records :  146\n"
     ]
    }
   ],
   "source": [
    "# Let look at some dataset statistcs\n",
    "print \"# of records : \", len(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of POIs:  18\n",
      "# of Non POIs:  128\n"
     ]
    }
   ],
   "source": [
    "# POIs vs Non POIs\n",
    "non_poi_count = 0\n",
    "for p in data_dict.values():\n",
    "    if p['poi']:\n",
    "        non_poi_count += 1\n",
    "print \"# of POIs: \", non_poi_count\n",
    "print \"# of Non POIs: \", len(data_dict) - non_poi_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of missing values in features: \n",
      "poi 0\n",
      "salary 51\n",
      "deferral_payments 107\n",
      "total_payments 21\n",
      "loan_advances 142\n",
      "bonus 64\n",
      "restricted_stock_deferred 128\n",
      "deferred_income 97\n",
      "total_stock_value 20\n",
      "expenses 51\n",
      "exercised_stock_options 44\n",
      "other 53\n",
      "long_term_incentive 80\n",
      "restricted_stock 36\n",
      "director_fees 129\n",
      "to_messages 60\n",
      "from_poi_to_this_person 60\n",
      "from_messages 60\n",
      "from_this_person_to_poi 60\n",
      "shared_receipt_with_poi 60\n"
     ]
    }
   ],
   "source": [
    "# Missing values in feautres\n",
    "print \"# of missing values in features: \"\n",
    "NaNInFeatures = [0 for i in range(len(features_list))]\n",
    "for i, person in enumerate(data_dict.values()):\n",
    "    for j, feature in enumerate(features_list):\n",
    "        if person[feature] == 'NaN':\n",
    "            NaNInFeatures[j] += 1\n",
    "\n",
    "for i, feature in enumerate(features_list):\n",
    "    print feature, NaNInFeatures[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METTS MARK                    BAXTER JOHN C                 ELLIOTT STEVEN                CORDES WILLIAM R              \n",
      "HANNON KEVIN P                MORDAUNT KRISTINA M           MEYER ROCKFORD G              MCMAHON JEFFREY               \n",
      "HORTON STANLEY C              PIPER GREGORY F               HUMPHREY GENE E               UMANOFF ADAM S                \n",
      "BLACHMAN JEREMY M             SUNDE MARTIN                  GIBBS DANA R                  LOWRY CHARLES P               \n",
      "COLWELL WESLEY                MULLER MARK S                 JACKSON CHARLENE R            WESTFAHL RICHARD K            \n",
      "WALTERS GARETH W              WALLS JR ROBERT H             KITCHEN LOUISE                CHAN RONNIE                   \n",
      "BELFER ROBERT                 SHANKMAN JEFFREY A            WODRASKA JOHN                 BERGSIEKER RICHARD P          \n",
      "URQUHART JOHN A               BIBI PHILIPPE A               RIEKER PAULA H                WHALEY DAVID A                \n",
      "BECK SALLY W                  HAUG DAVID L                  ECHOLS JOHN B                 MENDELSOHN JOHN               \n",
      "HICKERSON GARY J              CLINE KENNETH W               LEWIS RICHARD                 HAYES ROBERT E                \n",
      "MCCARTY DANNY J               KOPPER MICHAEL J              LEFF DANIEL P                 LAVORATO JOHN J               \n",
      "BERBERIAN DAVID               DETMERING TIMOTHY J           WAKEHAM JOHN                  POWERS WILLIAM                \n",
      "GOLD JOSEPH                   BANNANTINE JAMES M            DUNCAN JOHN H                 SHAPIRO RICHARD S             \n",
      "SHERRIFF JOHN R               SHELBY REX                    LEMAISTRE CHARLES             DEFFNER JOSEPH M              \n",
      "KISHKILL JOSEPH G             WHALLEY LAWRENCE G            MCCONNELL MICHAEL S           PIRO JIM                      \n",
      "DELAINEY DAVID W              SULLIVAN-SHAKLOVITZ COLLEEN   WROBEL BRUCE                  LINDHOLM TOD A                \n",
      "MEYER JEROME J                LAY KENNETH L                 BUTTS ROBERT H                OLSON CINDY K                 \n",
      "MCDONALD REBECCA              CUMBERLAND MICHAEL S          GAHN ROBERT S                 MCCLELLAN GEORGE              \n",
      "HERMANN ROBERT J              SCRIMSHAW MATTHEW             GATHMANN WILLIAM D            HAEDICKE MARK E               \n",
      "BOWEN JR RAYMOND M            GILLIS JOHN                   FITZGERALD JAY L              MORAN MICHAEL P               \n",
      "REDMOND BRIAN L               BAZELIDES PHILIP J            BELDEN TIMOTHY N              DURAN WILLIAM D               \n",
      "THORN TERENCE H               FASTOW ANDREW S               FOY JOE                       CALGER CHRISTOPHER F          \n",
      "RICE KENNETH D                KAMINSKI WINCENTY J           LOCKHART EUGENE E             COX DAVID                     \n",
      "OVERDYKE JR JERE C            PEREIRA PAULO V. FERRAZ       STABLER FRANK                 SKILLING JEFFREY K            \n",
      "BLAKE JR. NORMAN P            SHERRICK JEFFREY B            PRENTICE JAMES                GRAY RODNEY                   \n",
      "PICKERING MARK R              THE TRAVEL AGENCY IN THE PARK NOLES JAMES L                 KEAN STEVEN J                 \n",
      "TOTAL                         FOWLER PEGGY                  WASAFF GEORGE                 WHITE JR THOMAS E             \n",
      "CHRISTODOULOU DIOMEDES        ALLEN PHILLIP K               SHARP VICTORIA T              JAEDICKE ROBERT               \n",
      "WINOKUR JR. HERBERT S         BROWN MICHAEL                 BADUM JAMES P                 HUGHES JAMES A                \n",
      "REYNOLDS LAWRENCE             DIMICHELE RICHARD G           BHATNAGAR SANJAY              CARTER REBECCA C              \n",
      "BUCHANAN HAROLD G             YEAP SOON                     MURRAY JULIA H                GARLAND C KEVIN               \n",
      "DODSON KEITH                  YEAGER F SCOTT                HIRKO JOSEPH                  DIETRICH JANET R              \n",
      "DERRICK JR. JAMES V           FREVERT MARK A                PAI LOU L                     BAY FRANKLIN R                \n",
      "HAYSLETT RODERICK J           FUGH JOHN L                   FALLON JAMES B                KOENIG MARK E                 \n",
      "SAVAGE FRANK                  IZZO LAWRENCE L               TILNEY ELIZABETH A            MARTIN AMANDA K               \n",
      "BUY RICHARD B                 GRAMM WENDY L                 CAUSEY RICHARD A              TAYLOR MITCHELL S             \n",
      "DONAHUE JR JEFFREY M          GLISAN JR BEN F               \n"
     ]
    }
   ],
   "source": [
    "### Task 2: Remove outliers\n",
    "\n",
    "# Let's look at the names.\n",
    "s = []\n",
    "for person in data_dict.keys():\n",
    "    s.append(person)\n",
    "    if len(s) == 4:\n",
    "        print '{:<30}{:<30}{:<30}{:<30}'.format(s[0],s[1],s[2],s[3])\n",
    "        s = []\n",
    "print '{:<30}{:<30}'.format(s[0],s[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see above that there is a entry called \"TOTAL\". That obvisously cannot be a name. We would need to remove that from the dataset. Before we do, let's confirm it is what it the name suggests it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print out some values of the observation 'TOTAL'\n",
      "{'salary': 26704229, 'to_messages': 'NaN', 'deferral_payments': 32083396, 'total_payments': 309886585, 'exercised_stock_options': 311764000, 'bonus': 97343619, 'restricted_stock': 130322299, 'shared_receipt_with_poi': 'NaN', 'restricted_stock_deferred': -7576788, 'total_stock_value': 434509511, 'expenses': 5235198, 'loan_advances': 83925000, 'from_messages': 'NaN', 'other': 42667589, 'from_this_person_to_poi': 'NaN', 'poi': False, 'director_fees': 1398517, 'deferred_income': -27992891, 'long_term_incentive': 48521928, 'email_address': 'NaN', 'from_poi_to_this_person': 'NaN'}\n"
     ]
    }
   ],
   "source": [
    "print \"print out some values of the observation 'TOTAL'\"\n",
    "for name, person in data_dict.iteritems():\n",
    "\tif name == 'TOTAL':\n",
    "\t\tprint person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the sum of salary of all other persons is:  26704229.0\n"
     ]
    }
   ],
   "source": [
    "salary  = []\n",
    "for name, person in data_dict.iteritems():\n",
    "    if float(person['salary']) > 0:\n",
    "        salary.append(float(person['salary']))\n",
    "print \"the sum of salary of all other persons is: \",np.sum(salary)/2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the total salary matches to the salary against the \"TOTAL\" record in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bonus': 97343619,\n",
       " 'deferral_payments': 32083396,\n",
       " 'deferred_income': -27992891,\n",
       " 'director_fees': 1398517,\n",
       " 'email_address': 'NaN',\n",
       " 'exercised_stock_options': 311764000,\n",
       " 'expenses': 5235198,\n",
       " 'from_messages': 'NaN',\n",
       " 'from_poi_to_this_person': 'NaN',\n",
       " 'from_this_person_to_poi': 'NaN',\n",
       " 'loan_advances': 83925000,\n",
       " 'long_term_incentive': 48521928,\n",
       " 'other': 42667589,\n",
       " 'poi': False,\n",
       " 'restricted_stock': 130322299,\n",
       " 'restricted_stock_deferred': -7576788,\n",
       " 'salary': 26704229,\n",
       " 'shared_receipt_with_poi': 'NaN',\n",
       " 'to_messages': 'NaN',\n",
       " 'total_payments': 309886585,\n",
       " 'total_stock_value': 434509511}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's remove this TOTAL record.\n",
    "data_dict.pop('TOTAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bonus': 'NaN',\n",
       " 'deferral_payments': 'NaN',\n",
       " 'deferred_income': 'NaN',\n",
       " 'director_fees': 'NaN',\n",
       " 'email_address': 'NaN',\n",
       " 'exercised_stock_options': 'NaN',\n",
       " 'expenses': 'NaN',\n",
       " 'from_messages': 'NaN',\n",
       " 'from_poi_to_this_person': 'NaN',\n",
       " 'from_this_person_to_poi': 'NaN',\n",
       " 'loan_advances': 'NaN',\n",
       " 'long_term_incentive': 'NaN',\n",
       " 'other': 362096,\n",
       " 'poi': False,\n",
       " 'restricted_stock': 'NaN',\n",
       " 'restricted_stock_deferred': 'NaN',\n",
       " 'salary': 'NaN',\n",
       " 'shared_receipt_with_poi': 'NaN',\n",
       " 'to_messages': 'NaN',\n",
       " 'total_payments': 362096,\n",
       " 'total_stock_value': 'NaN'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There is a also a record which belongs to \"THE TRAVEL AGENCY IN THE PARK\". \n",
    "# This is not a person and hence should be removed.\n",
    "data_dict.pop(\"THE TRAVEL AGENCY IN THE PARK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of records after removal of TOTAL:  144\n"
     ]
    }
   ],
   "source": [
    "# No of records after removal of TOTAL & THE TRAVEL AGENCY IN THE PARK\n",
    "print \"No of records after removal of TOTAL: \", len(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we create two new features here 'to_poi_message_ratio' and 'from_poi_message_ratio' \n"
     ]
    }
   ],
   "source": [
    "### Task 3: Create new feature(s)\n",
    "\n",
    "### Store to my_dataset for easy export below.\n",
    "my_dataset = data_dict\n",
    "\n",
    "print \"we create two new features here 'to_poi_message_ratio' and 'from_poi_message_ratio' \"\n",
    "for person in my_dataset.values():\n",
    "    person['to_poi_message_ratio'] = 0\n",
    "    person['from_poi_message_ratio'] = 0\n",
    "    if float(person['from_messages']) > 0:\n",
    "        person['to_poi_message_ratio'] = float(person['from_this_person_to_poi'])/float(person['from_messages'])\n",
    "    if float(person['to_messages']) > 0:\n",
    "        person['from_poi_message_ratio'] = float(person['from_poi_to_this_person'])/float(person['to_messages'])\n",
    "    \n",
    "features_list.extend(['to_poi_message_ratio', 'from_poi_message_ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Extract features and labels from dataset for local testing\n",
    "data = featureFormat(my_dataset, features_list)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=6, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=10, splitter='best')\n",
      "\tAccuracy: 0.82573\tPrecision: 0.32356\tRecall: 0.28150\tF1: 0.30107\tF2: 0.28901\n",
      "\tTotal predictions: 15000\tTrue positives:  563\tFalse positives: 1177\tFalse negatives: 1437\tTrue negatives: 11823\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Task 4: Try a varity of classifiers\n",
    "### Please name your classifier clf for easy export below.\n",
    "### Note that if you want to do PCA or other multi-stage operations,\n",
    "### you'll need to use Pipelines. For more info:\n",
    "### http://scikit-learn.org/stable/modules/pipeline.html\n",
    "\n",
    "# Provided to give you a starting point. Try a variety of classifiers.\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "\n",
    "clf = DecisionTreeClassifier(min_samples_split=6, random_state=10)\n",
    "test_classifier(clf, my_dataset, features_list)\n",
    "\n",
    "#clf = ensemble.RandomForestClassifier(criterion='gini', n_estimators=14, max_depth=7,\n",
    "#                                      max_features=None, random_state=42, min_samples_split=1)\n",
    "#clf = AdaBoostClassifier(algorithm='SAMME')\n",
    "\n",
    "#params = dict(reduce_dim__n_components=[1, 2, 3], tree__min_samples_split=[2, 4, 6, 8 10])\n",
    "#clf = GridSearchCV(clf, param_grid=params, n_jobs=-1, scoring='recall')\n",
    "\n",
    "#test_classifier(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Task 5: Tune your classifier to achieve better than .3 precision and recall \n",
    "### using our testing script. Check the tester.py script in the final project\n",
    "### folder for details on the evaluation method, especially the test_classifier\n",
    "### function. Because of the small size of the dataset, the script uses\n",
    "### stratified shuffle split cross validation. For more info: \n",
    "### http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.html\n",
    "\n",
    "# Example starting point. Try investigating other evaluation techniques!\n",
    "from sklearn.cross_validation import train_test_split\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    train_test_split(features, labels, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Task 6: Dump your classifier, dataset, and features_list so anyone can\n",
    "### check your results. You do not need to change anything below, but make sure\n",
    "### that the version of poi_id.py that you submit can be run on its own and\n",
    "### generates the necessary .pkl files for validating your results.\n",
    "\n",
    "dump_classifier_and_data(clf, my_dataset, features_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
